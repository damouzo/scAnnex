/*
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    Generic SLURM executor configuration
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    For use on any HPC cluster with SLURM scheduler
    
    Usage: nextflow run main.nf -profile slurm,singularity
    
    Customize via command line:
      --slurm_queue 'your_partition'
      --slurm_account 'your_account'
      --max_memory '128.GB'
      --max_cpus 32
----------------------------------------------------------------------------------------
*/

params {
    // SLURM-specific parameters (can be overridden via command line)
    slurm_queue = null      // Default queue/partition (e.g., 'compute', 'short', 'long')
    slurm_account = null    // Account for billing/resource tracking
}

process {
    executor = 'slurm'
    
    // Generic SLURM options
    clusterOptions = { 
        def opts = []
        if (params.slurm_queue) opts << "--partition=${params.slurm_queue}"
        if (params.slurm_account) opts << "--account=${params.slurm_account}"
        opts.join(' ')
    }
    
    // Job naming for easy tracking in squeue
    beforeScript = 'echo "Job started on: $(hostname) at $(date)"'
    
    // SLURM-specific error codes for retry
    // 140: Exceeded memory limit
    // 143: SIGTERM (timeout)
    // 137: SIGKILL (out of memory)
    // 104: Connection reset
    // 134: SIGABRT
    // 139: SIGSEGV
    // 247: SLURM node failure
    errorStrategy = { task.exitStatus in [140,143,137,104,134,139,247] ? 'retry' : 'finish' }
    maxRetries = 2
    maxErrors = '-1'
    
    // Resource specifications per label
    // These can be overridden by specific HPC profiles (e.g., apocrita.config)
    
    withLabel: 'process_single' {
        cpus = 1
        memory = { 6.GB * task.attempt }
        time = { 4.h * task.attempt }
    }
    
    withLabel: 'process_low' {
        cpus = 2
        memory = { 12.GB * task.attempt }
        time = { 4.h * task.attempt }
    }
    
    withLabel: 'process_medium' {
        cpus = 6
        memory = { 36.GB * task.attempt }
        time = { 8.h * task.attempt }
    }
    
    withLabel: 'process_high' {
        cpus = 12
        memory = { 72.GB * task.attempt }
        time = { 16.h * task.attempt }
    }
    
    withLabel: 'process_long' {
        time = { 24.h * task.attempt }
    }
    
    withLabel: 'process_high_memory' {
        memory = { 200.GB * task.attempt }
    }
}

// Note: Software management (conda, singularity, docker) should be specified
// via additional profiles. Example:
//   nextflow run main.nf -profile slurm,singularity
//   nextflow run main.nf -profile slurm,conda
